name: deploy-jdk-ssm

on:
  workflow_dispatch:
    inputs:
      create_s3_bucket:
        description: 'Create new S3 bucket (false to use existing)'
        required: false
        default: 'true'
        type: choice
        options:
          - 'true'
          - 'false'
      create_vpc:
        description: 'Create new VPC (false to use existing)'
        required: false
        default: 'true'
        type: choice
        options:
          - 'true'
          - 'false'
      create_instances:
        description: 'Create EC2 instances'
        required: false
        default: 'true'
        type: choice
        options:
          - 'true'
          - 'false'
      instance_count:
        description: 'Number of instances to create'
        required: false
        default: '2'
        type: string
      destroy_resources:
        description: 'Destroy resources instead of creating'
        required: false
        default: 'false'
        type: choice
        options:
          - 'false'
          - 'instances-only'
          - 'all-except-s3'
          - 'everything'
      destroy_confirm:
        description: 'Type "DESTROY" to confirm destruction'
        required: false
        type: string
  push:
    branches: [ main ]

env:
  TF_VAR_create_s3_bucket: ${{ github.event.inputs.create_s3_bucket || 'true' }}
  TF_VAR_create_vpc: ${{ github.event.inputs.create_vpc || 'true' }}
  TF_VAR_create_instances: ${{ github.event.inputs.create_instances || 'true' }}
  TF_VAR_instance_count: ${{ github.event.inputs.instance_count || '2' }}

jobs:
  terraform_plan_apply:
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.destroy_resources == 'false' || github.event.inputs.destroy_resources == '' }}
    outputs:
      instance_ids: ${{ steps.set_outputs.outputs.instance_ids }}
      bucket: ${{ steps.set_outputs.outputs.bucket }}
      s3_key: ${{ steps.set_outputs.outputs.s3_key }}
      vpc_created: ${{ steps.set_outputs.outputs.vpc_created }}
      instances_created: ${{ steps.set_outputs.outputs.instances_created }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0
          terraform_wrapper: false

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Create Terraform backend bucket if needed
        run: |
          BACKEND_BUCKET="terraform-state-jdk-deployment-${{ github.repository_owner }}"
          if ! aws s3api head-bucket --bucket "$BACKEND_BUCKET" 2>/dev/null; then
            echo "Creating Terraform state bucket: $BACKEND_BUCKET"
            aws s3 mb "s3://$BACKEND_BUCKET" --region ${{ secrets.AWS_REGION }}
            aws s3api put-bucket-versioning --bucket "$BACKEND_BUCKET" --versioning-configuration Status=Enabled
            aws s3api put-bucket-encryption --bucket "$BACKEND_BUCKET" --server-side-encryption-configuration '{
              "Rules": [{"ApplyServerSideEncryptionByDefault": {"SSEAlgorithm": "AES256"}}]
            }'
          else
            echo "Terraform state bucket already exists: $BACKEND_BUCKET"
          fi
      - name: Create DynamoDB table for state locking
        run: |
          TABLE_NAME="terraform-state-lock-jdk"
          if ! aws dynamodb describe-table --table-name "$TABLE_NAME" 2>/dev/null; then
            echo "Creating DynamoDB table for state locking: $TABLE_NAME"
            aws dynamodb create-table \
              --table-name "$TABLE_NAME" \
              --attribute-definitions AttributeName=LockID,AttributeType=S \
              --key-schema AttributeName=LockID,KeyType=HASH \
              --billing-mode PAY_PER_REQUEST \
              --region ${{ secrets.AWS_REGION }}
            
            aws dynamodb wait table-exists --table-name "$TABLE_NAME"
          else
            echo "DynamoDB table already exists: $TABLE_NAME"
          fi
      - name: Initialize Terraform backend
        working-directory: terraform
        run: |
          BACKEND_BUCKET="terraform-state-jdk-deployment-${{ github.repository_owner }}"
          cat > backend.tf << EOF
          terraform {
            backend "s3" {
              bucket         = "$BACKEND_BUCKET"
              key            = "jdk-deployment/terraform.tfstate"
              region         = "${{ secrets.AWS_REGION }}"
              encrypt        = true
              dynamodb_table = "terraform-state-lock-jdk"
            }
          }
          EOF
          
          terraform init -reconfigure
      - name: Terraform plan
        working-directory: terraform
        run: |
          terraform plan \
            -var="local_installer_path=${{ github.workspace }}/files/OpenJDK21U-jdk_x64_windows_hotspot_21.0.8_9.msi" \
            -var="admin_password=${{ secrets.ADMIN_PASSWORD }}" \
            -var="aws_region=${{ secrets.AWS_REGION }}" \
            -var="key_pair_name=${{ secrets.KEY_PAIR_NAME }}" \
            -out=tfplan
      - name: Terraform apply
        working-directory: terraform
        run: terraform apply -auto-approve tfplan

      - name: Set job outputs from Terraform
        id: set_outputs
        working-directory: terraform
        run: |
          terraform output -json > tfout.json
          cat tfout.json
          
          INSTANCE_IDS=$(terraform output -raw instance_ids 2>/dev/null || echo "[]")
          BUCKET=$(terraform output -raw s3_bucket 2>/dev/null || echo "")
          S3_KEY=$(terraform output -raw s3_key 2>/dev/null || echo "")
          VPC_CREATED="${{ env.TF_VAR_create_vpc }}"
          INSTANCES_CREATED="${{ env.TF_VAR_create_instances }}"
          
          echo "instance_ids=$INSTANCE_IDS" >> $GITHUB_OUTPUT
          echo "bucket=$BUCKET" >> $GITHUB_OUTPUT
          echo "s3_key=$S3_KEY" >> $GITHUB_OUTPUT
          echo "vpc_created=$VPC_CREATED" >> $GITHUB_OUTPUT
          echo "instances_created=$INSTANCES_CREATED" >> $GITHUB_OUTPUT
          
          echo "Instance IDs: $INSTANCE_IDS"
          echo "Bucket: $BUCKET"
          echo "S3 Key: $S3_KEY"
          echo "VPC Created: $VPC_CREATED"
          echo "Instances Created: $INSTANCES_CREATED"
  ansible_deployment:
    needs: terraform_plan_apply
    runs-on: ubuntu-latest
    if: ${{ needs.terraform_plan_apply.outputs.instances_created == 'true' && needs.terraform_plan_apply.outputs.instance_ids != '[]' }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Setup Python and install dependencies
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Ansible and AWS dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ansible boto3 botocore
          ansible-galaxy collection install amazon.aws
      - name: Wait for instances to be ready
        env:
          INST_RAW: ${{ needs.terraform_plan_apply.outputs.instance_ids }}
        run: |
          echo "Waiting for instances to be ready for SSM..."
          if echo "$INST_RAW" | jq -e . >/dev/null 2>&1; then
            INSTANCE_IDS=$(echo "$INST_RAW" | jq -r '.[]' | tr '\n' ' ')
            
            for instance_id in $INSTANCE_IDS; do
              echo "Waiting for instance $instance_id to be ready..."
              aws ec2 wait instance-running --instance-ids "$instance_id"
              
              timeout=300
              while [ $timeout -gt 0 ]; do
                if aws ssm describe-instance-information --filters "Key=InstanceIds,Values=$instance_id" --query 'InstanceInformationList[0].PingStatus' --output text 2>/dev/null | grep -q "Online"; then
                  echo "Instance $instance_id is ready for SSM"
                  break
                fi
                echo "Waiting for SSM agent on $instance_id... ($timeout seconds remaining)"
                sleep 10
                timeout=$((timeout - 10))
              done
            done
          fi
      - name: Validate S3 object exists
        env:
          BUCKET: ${{ needs.terraform_plan_apply.outputs.bucket }}
          KEY: ${{ needs.terraform_plan_apply.outputs.s3_key }}
        run: |
          if [ -n "$BUCKET" ] && [ -n "$KEY" ]; then
            if aws s3api head-object --bucket "$BUCKET" --key "$KEY" >/dev/null 2>&1; then
              echo "S3 object validated: s3://$BUCKET/$KEY"
            else
              echo "Warning: S3 object s3://$BUCKET/$KEY does not exist"
              echo "JDK installer may need to be uploaded manually"
            fi
          else
            echo "Warning: S3 bucket or key not specified"
          fi
      - name: Generate presigned URL
        env:
          BUCKET: ${{ needs.terraform_plan_apply.outputs.bucket }}
          KEY: ${{ needs.terraform_plan_apply.outputs.s3_key }}
          EXPIRY: 1800
        run: |
          if [ -n "$BUCKET" ] && [ -n "$KEY" ]; then
            if aws s3api head-object --bucket "$BUCKET" --key "$KEY" >/dev/null 2>&1; then
              PRESIGNED_URL=$(aws s3 presign "s3://$BUCKET/$KEY" --expires-in $EXPIRY)
              echo "PRESIGNED_URL=$PRESIGNED_URL" >> $GITHUB_ENV
              echo "Presigned URL generated successfully"
            else
              echo "PRESIGNED_URL=" >> $GITHUB_ENV
              echo "No presigned URL generated - S3 object not found"
            fi
          else
            echo "PRESIGNED_URL=" >> $GITHUB_ENV
            echo "No presigned URL generated - bucket or key missing"
          fi
      - name: Normalize instance IDs
        env:
          INST_RAW: ${{ needs.terraform_plan_apply.outputs.instance_ids }}
        run: |
          echo "$INST_RAW" > inst_raw.txt
          if echo "$INST_RAW" | jq -e . >/dev/null 2>&1; then
            echo "$INST_RAW" | jq -c '.' > inst_list.json
          else
            echo '[]' > inst_list.json
          fi
          INST_JSON=$(cat inst_list.json)
          echo "INST_JSON=$INST_JSON" >> $GITHUB_ENV
          echo "Normalized instance IDs: $INST_JSON"
      - name: Run Ansible playbook via SSM
        env:
          PRESIGNED_URL: ${{ env.PRESIGNED_URL }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          INST_JSON: ${{ env.INST_JSON }}
          BUCKET: ${{ needs.terraform_plan_apply.outputs.bucket }}
          S3_KEY: ${{ needs.terraform_plan_apply.outputs.s3_key }}
        run: |
          if [ ! -f "ansible/ssm_install_jdk.yml" ]; then
            echo "Error: Ansible playbook not found at ansible/ssm_install_jdk.yml"
            exit 1
          fi
          
          echo "Running Ansible playbook on instances: $INST_JSON"
          
          ansible-playbook ansible/ssm_install_jdk.yml \
            -e "instance_ids=$INST_JSON" \
            -e "s3_bucket=$BUCKET" \
            -e "s3_key=$S3_KEY" \
            -e "presigned_url=$PRESIGNED_URL" \
            -e "aws_region=$AWS_REGION" \
            -v
      - name: Cleanup
        if: always()
        run: |
          rm -f inst_list.json inst_raw.txt
          echo "Cleanup completed"
  terraform_destroy:
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.destroy_resources != 'false' && github.event.inputs.destroy_resources != '' && github.event.inputs.destroy_confirm == 'DESTROY' }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0
          terraform_wrapper: false

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Create backup before destruction
        run: |
          echo "üìã Creating backup before destruction..."
          
          mkdir -p backups/$(date +%Y%m%d_%H%M%S)
          BACKUP_DIR="backups/$(date +%Y%m%d_%H%M%S)"
          
          cd terraform
          BACKEND_BUCKET="terraform-state-jdk-deployment-${{ github.repository_owner }}"
          cat > backend.tf << EOF
          terraform {
            backend "s3" {
              bucket         = "$BACKEND_BUCKET"
              key            = "jdk-deployment/terraform.tfstate"
              region         = "${{ secrets.AWS_REGION }}"
              encrypt        = true
              dynamodb_table = "terraform-state-lock-jdk"
            }
          }
          EOF
          
          if terraform init 2>/dev/null; then
            terraform show -json > "../$BACKUP_DIR/terraform-state.json" 2>/dev/null || echo "{}" > "../$BACKUP_DIR/terraform-state.json"
            terraform output -json > "../$BACKUP_DIR/terraform-outputs.json" 2>/dev/null || echo "{}" > "../$BACKUP_DIR/terraform-outputs.json"
            terraform state list > "../$BACKUP_DIR/resource-list.txt" 2>/dev/null || echo "No resources" > "../$BACKUP_DIR/resource-list.txt"
            echo "‚úÖ Backup created in: $BACKUP_DIR"
          else
            echo "‚ö†Ô∏è No Terraform state found to backup"
          fi
      - name: Initialize Terraform for destroy
        working-directory: terraform
        run: |
          BACKEND_BUCKET="terraform-state-jdk-deployment-${{ github.repository_owner }}"
          
          # Remove any existing backend.tf to avoid conflicts
          rm -f backend.tf
          
          # Create backend configuration for destroy
          cat > backend.tf << EOF
          terraform {
            backend "s3" {
              bucket         = "$BACKEND_BUCKET"
              key            = "jdk-deployment/terraform.tfstate"
              region         = "${{ secrets.AWS_REGION }}"
              encrypt        = true
              dynamodb_table = "terraform-state-lock-jdk"
            }
          }
          EOF
          
          echo "Initialized backend for destroy operation"
          terraform init
      - name: Selective destroy - Instances only
        if: ${{ github.event.inputs.destroy_resources == 'instances-only' }}
        working-directory: terraform
        run: |
          echo "üî• Destroying EC2 instances only..."
          terraform destroy -auto-approve \
            -target="aws_instance.windows_servers" \
            -target="aws_iam_instance_profile.ec2_profile" \
            -target="aws_iam_role.ec2_ssm_role" \
            -target="aws_iam_role_policy_attachment.ec2_ssm_policy" \
            -var="admin_password=${{ secrets.ADMIN_PASSWORD }}" \
            -var="aws_region=${{ secrets.AWS_REGION }}" \
            -var="key_pair_name=${{ secrets.KEY_PAIR_NAME }}" \
            -var="local_installer_path=${{ github.workspace }}/files/jdk-installer.msi"
      - name: Selective destroy - All except S3
        if: ${{ github.event.inputs.destroy_resources == 'all-except-s3' }}
        working-directory: terraform
        run: |
          echo "üî• Destroying all resources except S3..."
          
          terraform destroy -auto-approve \
            -target="aws_instance.windows_servers" \
            -target="aws_iam_instance_profile.ec2_profile" \
            -target="aws_iam_role.ec2_ssm_role" \
            -target="aws_iam_role_policy_attachment.ec2_ssm_policy" \
            -var="admin_password=${{ secrets.ADMIN_PASSWORD }}" \
            -var="aws_region=${{ secrets.AWS_REGION }}" \
            -var="key_pair_name=${{ secrets.KEY_PAIR_NAME }}" \
            -var="local_installer_path=${{ github.workspace }}/files/jdk-installer.msi"
          
          terraform destroy -auto-approve \
            -target="aws_security_group.windows_sg" \
            -target="aws_route_table_association.public" \
            -target="aws_route_table.public" \
            -target="aws_subnet.public" \
            -target="aws_internet_gateway.main" \
            -target="aws_vpc.main" \
            -var="admin_password=${{ secrets.ADMIN_PASSWORD }}" \
            -var="aws_region=${{ secrets.AWS_REGION }}" \
            -var="key_pair_name=${{ secrets.KEY_PAIR_NAME }}" \
            -var="local_installer_path=${{ github.workspace }}/files/jdk-installer.msi"
      - name: Destroy everything
        if: ${{ github.event.inputs.destroy_resources == 'everything' }}
        working-directory: terraform
        run: |
          echo "üí• Destroying ALL resources..."
          terraform destroy -auto-approve \
            -var="admin_password=${{ secrets.ADMIN_PASSWORD }}" \
            -var="aws_region=${{ secrets.AWS_REGION }}" \
            -var="key_pair_name=${{ secrets.KEY_PAIR_NAME }}" \
            -var="local_installer_path=${{ github.workspace }}/files/jdk-installer.msi"
      - name: Verify destruction
        run: |
          echo "üîç Verifying resource destruction..."
          
          INSTANCES=$(aws ec2 describe-instances --filters "Name=tag:Environment,Values=${{ env.TF_VAR_create_instances || 'dev' }}" "Name=instance-state-name,Values=running,pending,stopping,stopped" --query 'Reservations[].Instances[].InstanceId' --output text 2>/dev/null || true)
          if [ -n "$INSTANCES" ]; then
            echo "‚ö†Ô∏è WARNING: Found remaining instances: $INSTANCES"
          else
            echo "‚úÖ No instances found"
          fi
          
          echo "üéØ Destroy verification completed"
      - name: Destruction summary
        run: |
          echo "‚úÖ DESTRUCTION COMPLETED SUCCESSFULLY"
          echo "Scope: ${{ github.event.inputs.destroy_resources }}"
          echo "Timestamp: $(date)"
          echo ""
          echo "Next steps:"
          echo "1. Verify AWS console for remaining resources"
          echo "2. Check backup data if needed for restoration"
          echo "3. Update any dependent systems or documentation"
